{"backend_state":"running","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-c9ccf4a4-9a03-475a-92d8-03a74b9d83a3.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.5"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1619205013772,"exec_count":1,"id":"0ed92b","input":"import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import load_iris\nfrom sklearn.datasets import load_digits\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom mpl_toolkits.mplot3d import Axes3D\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.utils import shuffle\n# from sklearn.datasets import fetch_mldata\nfrom sklearn.cluster import KMeans","kernel":"python3","pos":1,"start":1619205010192,"state":"done","type":"cell"}
{"cell_type":"code","end":1619205024514,"exec_count":2,"id":"d9b007","input":"df = pd.read_csv('data/Wholesale customers data.csv')\ndf.head()","kernel":"python3","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Channel</th>\n      <th>Region</th>\n      <th>Fresh</th>\n      <th>Milk</th>\n      <th>Grocery</th>\n      <th>Frozen</th>\n      <th>Detergents_Paper</th>\n      <th>Delicassen</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>3</td>\n      <td>12669</td>\n      <td>9656</td>\n      <td>7561</td>\n      <td>214</td>\n      <td>2674</td>\n      <td>1338</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>3</td>\n      <td>7057</td>\n      <td>9810</td>\n      <td>9568</td>\n      <td>1762</td>\n      <td>3293</td>\n      <td>1776</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>3</td>\n      <td>6353</td>\n      <td>8808</td>\n      <td>7684</td>\n      <td>2405</td>\n      <td>3516</td>\n      <td>7844</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>3</td>\n      <td>13265</td>\n      <td>1196</td>\n      <td>4221</td>\n      <td>6404</td>\n      <td>507</td>\n      <td>1788</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>3</td>\n      <td>22615</td>\n      <td>5410</td>\n      <td>7198</td>\n      <td>3915</td>\n      <td>1777</td>\n      <td>5185</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   Channel  Region  Fresh  Milk  Grocery  Frozen  Detergents_Paper  Delicassen\n0        2       3  12669  9656     7561     214              2674        1338\n1        2       3   7057  9810     9568    1762              3293        1776\n2        2       3   6353  8808     7684    2405              3516        7844\n3        1       3  13265  1196     4221    6404               507        1788\n4        2       3  22615  5410     7198    3915              1777        5185"},"exec_count":2}},"pos":3,"start":1619205024435,"state":"done","type":"cell"}
{"cell_type":"code","end":1619205027379,"exec_count":3,"id":"f413fd","input":"#insert 1\nsc_X = StandardScaler()\nX = sc_X.fit_transform(df)\n\nSSE = []\nfor cluster in range(1,11):\n    model = KMeans(n_clusters = cluster, init='k-means++')\n    model.fit(X)\n    SSE.append(model.inertia_)\n\nframe = pd.DataFrame({'Cluster':range(1,11), 'SSE':SSE})\nplt.figure(figsize=(12,6))\nplt.plot(frame['Cluster'], frame['SSE'], marker='o')\nplt.xlabel('Number of clusters')\nplt.ylabel('Inertia')\nplt.xticks(np.arange(11))\n\nplt.show()","kernel":"python3","output":{"0":{"data":{"image/png":"162510d40d6a0570a60928069e5f1a2f0c7ad5b9","text/plain":"<Figure size 864x432 with 1 Axes>"},"metadata":{"image/png":{"height":370,"width":730},"needs_background":"light"}}},"pos":5,"start":1619205026409,"state":"done","type":"cell"}
{"cell_type":"code","end":1619205027989,"exec_count":4,"id":"db09ca","input":"#insert 2\nmodel = KMeans(n_clusters=2)\nmodel.fit(X)","kernel":"python3","output":{"0":{"data":{"text/plain":"KMeans(n_clusters=2)"},"exec_count":4}},"pos":7,"start":1619205027958,"state":"done","type":"cell"}
{"cell_type":"code","end":1619205028800,"exec_count":5,"id":"801a57","input":"model.predict([df.iloc[0]])","kernel":"python3","output":{"0":{"data":{"text/plain":"array([1], dtype=int32)"},"exec_count":5}},"pos":8,"start":1619205028793,"state":"done","type":"cell"}
{"cell_type":"code","end":1619205046777,"exec_count":6,"id":"161945","input":"#insert 3\nmini_df = df[['Fresh', 'Frozen']]\nmodel_ = KMeans(n_clusters=2)\nmodel_.fit(mini_df)\nx_ax = df['Fresh']\ny_ax = df['Frozen']\n\nplt.scatter(x_ax, y_ax, c=model_.labels_.astype(np.float), edgecolor='k')\nplt.xlabel('Fresh')\nplt.ylabel('Frozen')\n\nfor cluster in model_.cluster_centers_:\n    plt.plot(cluster[0], cluster[1], 'r*', markersize=12)\n\nplt.xlim((0, 50000))\nplt.ylim((0, 20000))\nplt.show()","kernel":"python3","output":{"0":{"data":{"image/png":"472e3ecb404c7d0ceb0500c6cc318a78f74b213b","text/plain":"<Figure size 432x288 with 1 Axes>"},"metadata":{"image/png":{"height":265,"width":417},"needs_background":"light"}}},"pos":10,"start":1619205046443,"state":"done","type":"cell"}
{"cell_type":"code","end":1619205048157,"exec_count":7,"id":"622e0c","input":"#insert 4\nimport random as rand\n\n\ndef k_means(points, c_count):\n    # setting up min and max\n    xs = [p[0] for p in points]\n    ys = [p[1] for p in points]\n    x_max, x_min = max(xs), min(xs)\n    y_max, y_min = max(ys), min(ys)\n            \n    # setting up centroids and the means dictionary\n    centroids = [[rand.uniform(x_min, x_max), rand.uniform(y_min, y_max)] for i in range(c_count)]\n    clust = dict()\n    labels = []\n    \n    # arbitary amount of trials\n    for i in range(10):\n        # remaking the empty slots of the means dictionary\n        for c in range(c_count):\n            clust[c] = []\n        \n        # looping through and setting up where each point would end\n        for p in points:\n            current_min = float('inf')\n            for c in range(c_count):\n                dist = ((centroids[c][0]-p[0])**2)+((centroids[c][1]-p[1])**2)\n                if dist < current_min:\n                    current_min = dist\n                    position = c\n            if i == 9:\n                labels.append(position)\n            clust[position].append(p)\n        \n    # editing the means\n    for c in range(c_count):\n        x_s = [p[0] for p in clust[c]]\n        y_s = [p[1] for p in clust[c]]\n        centroids[c] = [sum(x_s)/len(x_s), sum(y_s)/len(y_s)]\n    print(centroids)\n\n#     # returning the cluster, probably easier to see it like this instead of a long list anyways, and the other list thing if you insist...\n#     return clust, labels\n    return labels  # because you want it for the test >.>","kernel":"python3","pos":12,"start":1619205048152,"state":"done","type":"cell"}
{"cell_type":"code","end":1619205050644,"exec_count":8,"id":"4d7577","input":"#Create points containing just the milk and frozen values\npoints = [[row['Milk'], row['Frozen']] for index, row in df.iterrows()]\n\n#Run my own algorithm\nmylabels = k_means(points, 2)\n# print(mylabels)\n\n#Run sci-kit learn's algorithm\nmodel = KMeans(n_clusters=2)\nmodel.fit(X)\n\n#Compare the two labels\nfor index, row in df.iterrows():\n    print(mylabels[index], model.predict([row])[0])","kernel":"python3","output":{"0":{"name":"stdout","text":"[[21274.666666666668, 44137.333333333336], [5690.006864988558, 2790.0183066361556]]\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 0\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 0\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 0\n1 0\n1 1\n0 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 0\n1 0\n1 0\n1 1\n1 1\n1 1\n1 0\n1 1\n1 0\n1 1\n1 0\n1 1\n1 0\n1 0\n1 0\n1 1\n1 1\n1 0\n1 0\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n"},"1":{"name":"stdout","text":"1 1\n1 1\n1 1\n1 1\n1 0\n1 0\n1 1\n1 1\n1 1\n1 0\n1 0\n1 0\n1 1\n1 0\n1 1\n1 0\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n0 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 0\n1 0\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 0\n1 0\n1 0\n1 1\n1 0\n1 0\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 0\n1 0\n1 1\n1 0\n1 0\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 0\n1 0\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 0\n1 0\n1 1\n1 1\n1 1\n1 0\n1 0\n1 0\n1 0\n1 1\n1 0\n1 0\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 0\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 0\n0 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 0\n1 1\n1 0\n1 1\n1 0\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n"},"2":{"name":"stdout","text":"1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 0\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 0\n1 0\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 0\n1 0\n1 1\n1 1\n1 1\n1 0\n1 1\n1 0\n1 0\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 0\n1 0\n1 0\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 1\n1 0\n1 1\n1 1\n1 1\n"}},"pos":14,"start":1619205049962,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":0,"id":"2a43d2","input":"","pos":15,"type":"cell"}
{"cell_type":"markdown","id":"16e477","input":"5.To test your function on a more interesting dataset, let's return to our grocery example of milk versus frozen expenditures. Does your function and the sci-kit learn KMeans function predict similar labels using k=2 clusters? Note that the labels may be exactly the same or exactly the opposite (which still is fine) based on what label (0 or 1) each algorithm chose to use for each of the two groups.","pos":13,"type":"cell"}
{"cell_type":"markdown","id":"451959","input":"4.Create an algorithm called k_means that takes in a list of points and a number of clusters and returns a list of labels corresponding to each point's cluster. The function should also print the cluster centroids. For simplicity, let's assume that each point contains only two dimensions. Here's a simple example to test your output:\n\n```python\nprint('Labels: ', k_means([[4,2], [2,1], [0,3], [5,1], [2,6]], 2))\n```\n```\nCentroids:  [[1.3333333333333333, 3.3333333333333335], [4.5, 1.5]]\nLabels:  [1, 0, 0, 1, 0]\n```\n\nA few Python things that might help:\n\n1.To randomly select two points from a list of points:\n\n```pyton\nimport random\ncentroids = random.sample(points, 2)\n```\n\n2.To save the cluster labels of the points (i.e., the index of the centroid corresponding to the minimum distance between that point and all of the centroids), you can use something like:\n\n```python\nlabels.append(distances.index(min(distances)))\n```","pos":11,"type":"cell"}
{"cell_type":"markdown","id":"9fcc69","input":"3.Plot the unscaleed milk value (column #3) on the x-axis and the unscaled frozen value (column #5) on the y-axis, along with the clusters and the cluster centroids. You should see pretty clear separation between the two clusters.","pos":9,"type":"cell"}
{"cell_type":"markdown","id":"a426a3","input":"1. Scale the data and then plot the number of clusters versus the inertia for cluster sizes of 1 to 10 to find that the elbow of the curve occurs at k=2:","pos":4,"type":"cell"}
{"cell_type":"markdown","id":"aca8f5","input":"Let's explore the wholesale customer dataset from 2011.\n\nThe data set refers to clients of a wholesale distributor. It includes the annual spending according to certain categories:\n    \nhttps://archive.ics.uci.edu/ml/datasets/wholesale+customers\n        ","pos":2,"type":"cell"}
{"cell_type":"markdown","id":"ec9f95","input":"Read in the relevant imports below:","pos":0,"type":"cell"}
{"cell_type":"markdown","id":"f84b30","input":"2.Using k=2, predict the category of the first item in the dataset.","pos":6,"type":"cell"}
{"id":0,"time":1619204847305,"type":"user"}
{"last_load":1619204846621,"type":"file"}