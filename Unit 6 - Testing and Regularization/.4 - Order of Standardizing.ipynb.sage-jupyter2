{"backend_state":"running","connection_file":"/tmp/xdg-runtime-user/jupyter/kernel-90318e8c-3bb5-4c74-b168-2127d12be63d.json","kernel":"python3","kernel_error":"","kernel_state":"idle","kernel_usage":{"cpu":0,"memory":0},"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"trust":true,"type":"settings"}
{"cell_type":"code","end":1608092452254,"exec_count":3,"id":"45fe60","input":"import pandas as pd\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import RidgeCV\nimport numpy as np\n\nfrom sklearn.preprocessing import PolynomialFeatures\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import make_pipeline\nimport matplotlib.pyplot as plt\n%matplotlib inline","kernel":"python3","pos":0,"start":1608092452247,"state":"done","type":"cell"}
{"cell_type":"code","end":1608092453774,"exec_count":4,"id":"3c994f","input":"df = pd.read_csv('data/students2.csv')\ndf.head()","kernel":"python3","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>gender</th>\n      <th>athletic</th>\n      <th>gpa</th>\n      <th>happiness</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20</td>\n      <td>F</td>\n      <td>Yes</td>\n      <td>2.1</td>\n      <td>11.180340</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25</td>\n      <td>M</td>\n      <td>No</td>\n      <td>3.9</td>\n      <td>-6.180340</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25</td>\n      <td>M</td>\n      <td>No</td>\n      <td>3.0</td>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18</td>\n      <td>M</td>\n      <td>Yes</td>\n      <td>2.7</td>\n      <td>6.669775</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16</td>\n      <td>F</td>\n      <td>Yes</td>\n      <td>2.3</td>\n      <td>13.302487</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   age gender athletic  gpa  happiness\n0   20      F      Yes  2.1  11.180340\n1   25      M       No  3.9  -6.180340\n2   25      M       No  3.0   1.000000\n3   18      M      Yes  2.7   6.669775\n4   16      F      Yes  2.3  13.302487"},"exec_count":4}},"pos":2,"start":1608092453752,"state":"done","type":"cell"}
{"cell_type":"code","exec_count":10,"id":"809243","input":"model.predict([X.iloc[0]])","output":{"0":{"data":{"text/plain":"array([11.56067293])"},"exec_count":10,"output_type":"execute_result"}},"pos":18,"type":"cell"}
{"cell_type":"code","exec_count":11,"id":"72744b","input":"numerical = scaler.transform(poly.transform([[20,2.1]]))\nnumerical","output":{"0":{"data":{"text/plain":"array([[ 0.        ,  0.20027184, -1.52721063,  0.10435851, -0.96964845,\n        -1.38798465,  0.00863644, -0.61468425, -1.18317922, -1.25564073,\n        -0.08232658, -0.49086585, -0.90929502, -1.15351775, -1.13475499,\n        -0.16525486, -0.45297666, -0.74126512, -0.96720752, -1.07167231,\n        -1.02768376]])"},"exec_count":11,"output_type":"execute_result"}},"pos":20,"type":"cell"}
{"cell_type":"code","exec_count":12,"id":"c03fd9","input":"inputdata = np.concatenate(([1,0,0,1], numerical[0]), axis=0)\ninputdata","output":{"0":{"data":{"text/plain":"array([ 1.        ,  0.        ,  0.        ,  1.        ,  0.        ,\n        0.20027184, -1.52721063,  0.10435851, -0.96964845, -1.38798465,\n        0.00863644, -0.61468425, -1.18317922, -1.25564073, -0.08232658,\n       -0.49086585, -0.90929502, -1.15351775, -1.13475499, -0.16525486,\n       -0.45297666, -0.74126512, -0.96720752, -1.07167231, -1.02768376])"},"exec_count":12,"output_type":"execute_result"}},"pos":22,"type":"cell"}
{"cell_type":"code","exec_count":13,"id":"a4299a","input":"model.predict([inputdata])","output":{"0":{"data":{"text/plain":"array([11.56067293])"},"exec_count":13,"output_type":"execute_result"}},"pos":24,"type":"cell"}
{"cell_type":"code","exec_count":14,"id":"81d09f","input":"df = pd.read_csv('students2.csv')\none_hot_gender = pd.get_dummies(df['gender'])\none_hot_athletic = pd.get_dummies(df['athletic'])\none_hot = one_hot_gender.join(one_hot_athletic)\n\ny = df['happiness']\nnumerical = df.drop(columns = ['gender', 'athletic', 'happiness'])\n\nmodel = make_pipeline(PolynomialFeatures(5), StandardScaler())\nmodel.fit(numerical)\nX = one_hot.join(pd.DataFrame(model.transform(numerical)))\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 99)\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\nprint(model.score(X_test, y_test))","output":{"0":{"name":"stdout","output_type":"stream","text":"0.9881909048273082\n"}},"pos":26,"type":"cell"}
{"cell_type":"code","exec_count":27,"id":"1c74ea","input":"df = pd.read_csv('students2.csv')\none_hot_gender = pd.get_dummies(df['gender'])\none_hot_athletic = pd.get_dummies(df['athletic'])\none_hot = one_hot_gender.join(one_hot_athletic)\n\ny = df['happiness']\nnumerical = df.drop(columns = ['gender', 'athletic', 'happiness'])\n\nmodel = make_pipeline(PolynomialFeatures(5), StandardScaler())\nmodel.fit(numerical)\nX = one_hot.join(pd.DataFrame(model.transform(numerical)))\n\nmodel = RidgeCV(cv=10, alphas=[0.0001, 0.1, 1])\nmodel.fit(X, y)\nprint(model.score(X, y))","output":{"0":{"name":"stdout","output_type":"stream","text":"0.9695292992508375\n"}},"pos":28,"type":"cell"}
{"cell_type":"code","exec_count":3,"id":"f8f8f1","input":"one_hot_gender = pd.get_dummies(df['gender'])\none_hot_athletic = pd.get_dummies(df['athletic'])\none_hot = one_hot_gender.join(one_hot_athletic)\none_hot.head()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>F</th>\n      <th>M</th>\n      <th>No</th>\n      <th>Yes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   F  M  No  Yes\n0  1  0   0    1\n1  0  1   1    0\n2  0  1   1    0\n3  0  1   0    1\n4  1  0   0    1"},"exec_count":3,"output_type":"execute_result"}},"pos":4,"type":"cell"}
{"cell_type":"code","exec_count":4,"id":"84e3c7","input":"y = df['happiness']\ndf = df.drop(columns = ['gender', 'athletic', 'happiness'])\ndf.head()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>gpa</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>20</td>\n      <td>2.1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>25</td>\n      <td>3.9</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>18</td>\n      <td>2.7</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>16</td>\n      <td>2.3</td>\n    </tr>\n  </tbody>\n</table>\n</div>","text/plain":"   age  gpa\n0   20  2.1\n1   25  3.9\n2   25  3.0\n3   18  2.7\n4   16  2.3"},"exec_count":4,"output_type":"execute_result"}},"pos":6,"type":"cell"}
{"cell_type":"code","exec_count":5,"id":"51369e","input":"X_train, X_test, y_train, y_test = train_test_split(df, y, test_size=0.3,random_state = 99)\n\nmindegree = 3\nmaxdegree = 20\ntrain_error = []\ntest_error = []\nfor deg in range(mindegree,maxdegree):\n    model = make_pipeline(PolynomialFeatures(deg),LinearRegression())\n    model.fit(X_train,y_train)\n    train_error.append(mean_squared_error(y_train,model.predict(X_train)))\n    test_error.append(mean_squared_error(y_test,model.predict(X_test)))\nprint(train_error,test_error)\nplt.plot(np.arange(mindegree,maxdegree), train_error, color='green', label='train')\nplt.plot(np.arange(mindegree,maxdegree), test_error, color='red', label='test')\nplt.ylabel('mean squared error')\nplt.xlabel('degree')\nplt.legend(loc='upper left')","output":{"0":{"name":"stdout","output_type":"stream","text":"[12.518761892323983, 7.815840369582714, 3.195566202879364, 3.203339110888255, 3.470486125621505, 3.166583041931805, 3.0434177178829245, 4.242696779811852, 4.121928900171849, 3.1188400874363786, 3.4740209701244136, 3.3617607859336096, 4.2189079533802465, 6.221672305894211, 4.7331028521777165, 6.20995020536376, 7.170580427648619] [9.553201143246474, 5.511964061308067, 3.3819023277872087, 3.9664013039645, 3.618994568401632, 3.751096313982727, 3.649623842172279, 4.843253161296319, 5.11789878290303, 3.820568225731637, 4.07486118954603, 3.930360992854251, 5.537179132055803, 8.809240352249498, 5.691325516652167, 7.2769048321950836, 8.333232143720316]\n"},"1":{"data":{"text/plain":"<matplotlib.legend.Legend at 0x10635f828>"},"exec_count":5,"output_type":"execute_result"},"2":{"data":{"image/png":"c265b25f83e92596eaa5a6a6218bb44c3d63b872","text/plain":"<Figure size 432x288 with 1 Axes>"},"exec_count":5,"metadata":{"needs_background":"light"},"output_type":"execute_result"}},"pos":8,"type":"cell"}
{"cell_type":"code","exec_count":6,"id":"d42a4e","input":"poly = PolynomialFeatures(5)\npoly.fit(df)\ndf_poly = poly.transform(df)\ndf_poly","output":{"0":{"data":{"text/plain":"array([[1.0000000e+00, 2.0000000e+01, 2.1000000e+00, ..., 3.7044000e+03,\n        3.8896200e+02, 4.0841010e+01],\n       [1.0000000e+00, 2.5000000e+01, 3.9000000e+00, ..., 3.7074375e+04,\n        5.7836025e+03, 9.0224199e+02],\n       [1.0000000e+00, 2.5000000e+01, 3.0000000e+00, ..., 1.6875000e+04,\n        2.0250000e+03, 2.4300000e+02],\n       ...,\n       [1.0000000e+00, 1.8000000e+01, 3.6000000e+00, ..., 1.5116544e+04,\n        3.0233088e+03, 6.0466176e+02],\n       [1.0000000e+00, 2.4000000e+01, 2.9000000e+00, ..., 1.4048064e+04,\n        1.6974744e+03, 2.0511149e+02],\n       [1.0000000e+00, 1.9000000e+01, 2.7000000e+00, ..., 7.1055630e+03,\n        1.0097379e+03, 1.4348907e+02]])"},"exec_count":6,"output_type":"execute_result"}},"pos":10,"type":"cell"}
{"cell_type":"code","exec_count":7,"id":"59f431","input":"scaler = StandardScaler()\nscaler.fit(df_poly)\nX_scaled = scaler.transform(df_poly)\nX_scaled","output":{"0":{"data":{"text/plain":"array([[ 0.        ,  0.20027184, -1.52721063, ..., -0.96720752,\n        -1.07167231, -1.02768376],\n       [ 0.        ,  1.49813743,  1.56299119, ...,  3.26995996,\n         2.82039691,  2.00023843],\n       [ 0.        ,  1.49813743,  0.01789028, ...,  0.70513529,\n         0.1086794 , -0.31707197],\n       ...,\n       [ 0.        , -0.31887439,  1.04795756, ...,  0.48185456,\n         0.82892887,  0.95421015],\n       [ 0.        ,  1.23856431, -0.1537876 , ...,  0.34618383,\n        -0.12762036, -0.45025438],\n       [ 0.        , -0.05930127, -0.49714336, ..., -0.53534333,\n        -0.62380135, -0.66686418]])"},"exec_count":7,"output_type":"execute_result"}},"pos":12,"type":"cell"}
{"cell_type":"code","exec_count":8,"id":"b8e3bd","input":"X = one_hot.join(pd.DataFrame(X_scaled))\nX.head()","output":{"0":{"data":{"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>F</th>\n      <th>M</th>\n      <th>No</th>\n      <th>Yes</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n      <th>5</th>\n      <th>...</th>\n      <th>11</th>\n      <th>12</th>\n      <th>13</th>\n      <th>14</th>\n      <th>15</th>\n      <th>16</th>\n      <th>17</th>\n      <th>18</th>\n      <th>19</th>\n      <th>20</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.200272</td>\n      <td>-1.527211</td>\n      <td>0.104359</td>\n      <td>-0.969648</td>\n      <td>-1.387985</td>\n      <td>...</td>\n      <td>-0.490866</td>\n      <td>-0.909295</td>\n      <td>-1.153518</td>\n      <td>-1.134755</td>\n      <td>-0.165255</td>\n      <td>-0.452977</td>\n      <td>-0.741265</td>\n      <td>-0.967208</td>\n      <td>-1.071672</td>\n      <td>-1.027684</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.498137</td>\n      <td>1.562991</td>\n      <td>1.626621</td>\n      <td>2.531790</td>\n      <td>1.692069</td>\n      <td>...</td>\n      <td>2.644010</td>\n      <td>3.049076</td>\n      <td>2.751191</td>\n      <td>1.912490</td>\n      <td>1.973792</td>\n      <td>2.721135</td>\n      <td>3.210679</td>\n      <td>3.269960</td>\n      <td>2.820397</td>\n      <td>2.000238</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>1.498137</td>\n      <td>0.017890</td>\n      <td>1.626621</td>\n      <td>1.112288</td>\n      <td>-0.078962</td>\n      <td>...</td>\n      <td>1.645217</td>\n      <td>1.064714</td>\n      <td>0.320141</td>\n      <td>-0.249586</td>\n      <td>1.973792</td>\n      <td>1.781382</td>\n      <td>1.315881</td>\n      <td>0.705135</td>\n      <td>0.108679</td>\n      <td>-0.317072</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>-0.318874</td>\n      <td>-0.497143</td>\n      <td>-0.409828</td>\n      <td>-0.553261</td>\n      <td>-0.566637</td>\n      <td>...</td>\n      <td>-0.565698</td>\n      <td>-0.603577</td>\n      <td>-0.644805</td>\n      <td>-0.650178</td>\n      <td>-0.592187</td>\n      <td>-0.593486</td>\n      <td>-0.599977</td>\n      <td>-0.627816</td>\n      <td>-0.662143</td>\n      <td>-0.666864</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>-0.838021</td>\n      <td>-1.183855</td>\n      <td>-0.869889</td>\n      <td>-1.297711</td>\n      <td>-1.137017</td>\n      <td>...</td>\n      <td>-1.014975</td>\n      <td>-1.118793</td>\n      <td>-1.125078</td>\n      <td>-1.012000</td>\n      <td>-0.866178</td>\n      <td>-0.948210</td>\n      <td>-1.007079</td>\n      <td>-1.042078</td>\n      <td>-1.029262</td>\n      <td>-0.945000</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 25 columns</p>\n</div>","text/plain":"   F  M  No  Yes    0         1         2         3         4         5  ...  \\\n0  1  0   0    1  0.0  0.200272 -1.527211  0.104359 -0.969648 -1.387985  ...   \n1  0  1   1    0  0.0  1.498137  1.562991  1.626621  2.531790  1.692069  ...   \n2  0  1   1    0  0.0  1.498137  0.017890  1.626621  1.112288 -0.078962  ...   \n3  0  1   0    1  0.0 -0.318874 -0.497143 -0.409828 -0.553261 -0.566637  ...   \n4  1  0   0    1  0.0 -0.838021 -1.183855 -0.869889 -1.297711 -1.137017  ...   \n\n         11        12        13        14        15        16        17  \\\n0 -0.490866 -0.909295 -1.153518 -1.134755 -0.165255 -0.452977 -0.741265   \n1  2.644010  3.049076  2.751191  1.912490  1.973792  2.721135  3.210679   \n2  1.645217  1.064714  0.320141 -0.249586  1.973792  1.781382  1.315881   \n3 -0.565698 -0.603577 -0.644805 -0.650178 -0.592187 -0.593486 -0.599977   \n4 -1.014975 -1.118793 -1.125078 -1.012000 -0.866178 -0.948210 -1.007079   \n\n         18        19        20  \n0 -0.967208 -1.071672 -1.027684  \n1  3.269960  2.820397  2.000238  \n2  0.705135  0.108679 -0.317072  \n3 -0.627816 -0.662143 -0.666864  \n4 -1.042078 -1.029262 -0.945000  \n\n[5 rows x 25 columns]"},"exec_count":8,"output_type":"execute_result"}},"pos":14,"type":"cell"}
{"cell_type":"code","exec_count":9,"id":"3a23b9","input":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3,random_state = 99)\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\nprint(model.score(X_test, y_test))","output":{"0":{"name":"stdout","output_type":"stream","text":"0.9881909048273082\n"}},"pos":16,"type":"cell"}
{"cell_type":"markdown","id":"2b33af","input":"You decide to use degree 5, so apply polynomial features to the NUMERICAL explanatory variables. ","pos":9,"type":"cell"}
{"cell_type":"markdown","id":"2cd93a","input":"Then join it with the categorical data (Female yes, Male no, non-athletic No, athletic Yes):","pos":21,"type":"cell"}
{"cell_type":"markdown","id":"421554","input":"What is the happiness of the first student predicted to be using this model?","pos":17,"type":"cell"}
{"cell_type":"markdown","id":"5c8c7d","input":"We should apply polynomial features BEFORE we scale, so let's explore the best polynomial to use:","pos":7,"type":"cell"}
{"cell_type":"markdown","id":"5cac80","input":"Finally, we can merge the transformed numerical data with the categorical data:","pos":13,"type":"cell"}
{"cell_type":"markdown","id":"6e5230","input":"Now predict her happiness:","pos":23,"type":"cell"}
{"cell_type":"markdown","id":"728a91","input":"If you wanted to use a pipeline, this would be the entire process:","pos":25,"type":"cell"}
{"cell_type":"markdown","id":"86088f","input":"### Two good articles\n\nhttps://medium.com/@samchaaa/preprocessing-why-you-should-generate-polynomial-features-first-before-standardizing-892b4326a91d\n    \nhttps://towardsdatascience.com/preprocessing-with-sklearn-a-complete-and-comprehensive-guide-670cb98fcfb9\n\n### Rule #1: Don’t standardize dummy variables.\n\n### Rule #2: Always standardize AFTER generating PolynomialFeatures.\n\nAs an example, let's first read in a stupid made up data set containing two numerical explanatory variables (GPA and age), two categorical (athletic and gender), and a response variable, happiness.\n","pos":1,"type":"cell"}
{"cell_type":"markdown","id":"882e34","input":"First, create a one-hot matrix for the categorical data:","pos":3,"type":"cell"}
{"cell_type":"markdown","id":"8da242","input":"Put these categorical variables aside for now and drop them from the dataframe, so that we have only the numerical explanatory variables left:","pos":5,"type":"cell"}
{"cell_type":"markdown","id":"a21ee6","input":"What if you actually wanted to input this student? (Age 20, gpa 2.1, female, athletic).\nFirst transform the numerical data:","pos":19,"type":"cell"}
{"cell_type":"markdown","id":"ce089a","input":"Or using RidgeCV:","pos":27,"type":"cell"}
{"cell_type":"markdown","id":"fb41e4","input":"And apply a regression:","pos":15,"type":"cell"}
{"cell_type":"markdown","id":"ff86f2","input":"Now, we will scale this transformed data. For now, we'll scale the entire dataset, but really you should only scale the training set so that information from the testing set doesn't leak in:","pos":11,"type":"cell"}
{"id":0,"time":1608092404018,"type":"user"}
{"last_load":1608092403954,"type":"file"}